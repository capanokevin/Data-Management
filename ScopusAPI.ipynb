{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "ScopusAPI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import data in mongo db"
      ],
      "metadata": {
        "id": "irxeb30fJcOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo[srv] --quiet"
      ],
      "metadata": {
        "id": "M58X-qZnJgki",
        "outputId": "18b62648-ee29-45ab-a2c7-078b4ce0c55c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 204 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 215 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 225 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 245 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 5.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dnspython --quiet"
      ],
      "metadata": {
        "id": "Ip3e00qXxRHc",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prima di importare i moduli riavviare il runtime ...\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import dns"
      ],
      "metadata": {
        "id": "xw8iJKgsty4I",
        "execution": {
          "iopub.status.busy": "2022-03-08T12:15:36.585179Z",
          "iopub.execute_input": "2022-03-08T12:15:36.586203Z",
          "iopub.status.idle": "2022-03-08T12:15:37.039469Z",
          "shell.execute_reply.started": "2022-03-08T12:15:36.586085Z",
          "shell.execute_reply": "2022-03-08T12:15:37.038624Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usiamo pymongo come driver verso mongoDB \n",
        "client = pymongo.MongoClient(\"mongodb+srv://capanokevin:1234@cluster0.u1mid.mongodb.net/DataMan?retryWrites=true&w=majority\")\n",
        "db = client.DataMan\n",
        "users = db.users"
      ],
      "metadata": {
        "id": "N9ofbpant9uv",
        "execution": {
          "iopub.status.busy": "2022-03-08T12:15:37.040805Z",
          "iopub.execute_input": "2022-03-08T12:15:37.041312Z",
          "iopub.status.idle": "2022-03-08T12:15:37.504434Z",
          "shell.execute_reply.started": "2022-03-08T12:15:37.041267Z",
          "shell.execute_reply": "2022-03-08T12:15:37.503513Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMANDI UTILI\n",
        "result = users.delete_many({}) #elimina tutti i record della collezione\n",
        "# result = users.insert_one(documento)\n",
        "# result = users.insert_many(dizionario di dizionari)"
      ],
      "metadata": {
        "id": "t_hYCHFJUdqT",
        "execution": {
          "iopub.status.busy": "2022-03-08T13:07:06.932207Z",
          "iopub.execute_input": "2022-03-08T13:07:06.932559Z",
          "iopub.status.idle": "2022-03-08T13:07:07.857571Z",
          "shell.execute_reply.started": "2022-03-08T13:07:06.932520Z",
          "shell.execute_reply": "2022-03-08T13:07:07.856605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Una volta messo il file json qui su server, lo mando diretto su mongo ... in realtà bisognerebbe mandarli uno a uno o in blocco ma qui possiamo\n",
        "# permetterci questo ...\n",
        "import json\n",
        "data = []\n",
        "with open('/content/sample_data/json.json') as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "result = users.insert_many(data)"
      ],
      "metadata": {
        "id": "n9KeAhBZT9mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scopus API acquisition ... after a hundred attempts ..."
      ],
      "metadata": {
        "id": "Uzo5YF43UpRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pybliometrics --quiet"
      ],
      "metadata": {
        "id": "8qTlteaUmc4T",
        "outputId": "79c03bd8-0048-4816-d8e9-90d717a9d618",
        "execution": {
          "iopub.status.busy": "2022-03-08T12:17:26.642609Z",
          "iopub.execute_input": "2022-03-08T12:17:26.642968Z",
          "iopub.status.idle": "2022-03-08T12:17:41.809570Z",
          "shell.execute_reply.started": "2022-03-08T12:17:26.642929Z",
          "shell.execute_reply": "2022-03-08T12:17:41.808480Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 918 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 39.2 MB/s \n",
            "\u001b[?25h  Building wheel for pybliometrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Qui devo mettere chiave API e successivamente anche Inst-Token\n",
        "from pybliometrics.scopus import ScopusSearch\n",
        "from pybliometrics.scopus import AuthorRetrieval"
      ],
      "metadata": {
        "id": "jLddWORIVZIv",
        "outputId": "b5bb6bef-67ff-4a47-a93c-e662765cfe9f",
        "execution": {
          "iopub.status.busy": "2022-03-08T12:17:41.812063Z",
          "iopub.execute_input": "2022-03-08T12:17:41.813140Z",
          "iopub.status.idle": "2022-03-08T12:17:57.555436Z",
          "shell.execute_reply.started": "2022-03-08T12:17:41.813084Z",
          "shell.execute_reply": "2022-03-08T12:17:57.554391Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating config file at /root/.pybliometrics/config.ini with default paths...\n",
            "Please enter your API Key(s), obtained from http://dev.elsevier.com/myapikey.html.  Separate multiple keys by comma:\n",
            "1f9a022c584f3a5744a5599fc6cca5c0\n",
            "API Keys are sufficient for most users.  If you have an InstToken, please enter the token now; otherwise just press Enter:\n",
            "6e61bb9b91753b832e19d6dd379f17ff\n",
            "Configuration file successfully created at /root/.pybliometrics/config.ini\n",
            "For details see https://pybliometrics.rtfd.io/en/stable/configuration.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T12:18:02.343874Z",
          "iopub.execute_input": "2022-03-08T12:18:02.344258Z",
          "iopub.status.idle": "2022-03-08T12:18:02.348535Z",
          "shell.execute_reply.started": "2022-03-08T12:18:02.344211Z",
          "shell.execute_reply": "2022-03-08T12:18:02.347696Z"
        },
        "trusted": true,
        "id": "PQsasc26mGSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_titles_list(post):\n",
        "    lower_list = []\n",
        "    upper_list = []\n",
        "    for idx, pub in enumerate(post['Publications']):\n",
        "        no_punctuation = pub['Title'].translate(str.maketrans('', '', string.punctuation))      # elimino la punteggiatura     \n",
        "        title = no_punctuation.strip()                                                          # elimino gli spazi esterni\n",
        "        lower_list.append(title.lower())\n",
        "        upper_list.append(title)\n",
        "       # print(lower, upper)\n",
        "    return lower_list, upper_list"
      ],
      "metadata": {
        "id": "hO4vNtEXmZjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns me the list of queries to use in ScopusSearch ... ottengo una lista con le query di tutti gli \n",
        "# articoli che ha scritto \n",
        "\n",
        "def get_query_list(lista):\n",
        "    query_list = []\n",
        "    for idx, pub in enumerate(lista):\n",
        "        publication = pub.split(' ')\n",
        "        query = 'TITLE-ABS-KEY ( ' \n",
        "        for idx2,word in enumerate(publication):\n",
        "            if idx2 == len(publication) - 1:\n",
        "                query = query + word + ' ) '\n",
        "            else:\n",
        "                query = query + word + ' AND '\n",
        "        query_list.append(query)\n",
        "    return query_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T12:18:06.809637Z",
          "iopub.execute_input": "2022-03-08T12:18:06.810204Z",
          "iopub.status.idle": "2022-03-08T12:18:06.819558Z",
          "shell.execute_reply.started": "2022-03-08T12:18:06.810153Z",
          "shell.execute_reply": "2022-03-08T12:18:06.818534Z"
        },
        "trusted": true,
        "id": "9t4FROH1mGSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that hopefully will guess the right spell of the name ... we'll see ...\n",
        "\n",
        "def get_author_name(post):\n",
        "    name = post['Name']\n",
        "    surname = post['Surname']\n",
        "    surname_name = surname + ', ' + name \n",
        "    return surname_name"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T12:18:26.780786Z",
          "iopub.execute_input": "2022-03-08T12:18:26.781480Z",
          "iopub.status.idle": "2022-03-08T12:18:26.786520Z",
          "shell.execute_reply.started": "2022-03-08T12:18:26.781423Z",
          "shell.execute_reply": "2022-03-08T12:18:26.785896Z"
        },
        "trusted": true,
        "id": "ePgrul6MmGSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that catch the Scopus Author ID and query the database ...\n",
        "\n",
        "def get_author_id(query_list, name):\n",
        "    i = 1\n",
        "    for query in query_list[0:i]:\n",
        "        try:\n",
        "            search = ScopusSearch(query)\n",
        "            df = pd.DataFrame(pd.DataFrame(search.results))\n",
        "            title = df['title'][0].translate(str.maketrans('', '', string.punctuation)).strip()\n",
        "            while title != upper[i]:\n",
        "                continue\n",
        "            author_names = list(df['author_names'][0].split(';'))    \n",
        "            author_IDs = list(df['author_ids'][0].split(';'))\n",
        "            print(author_names, author_IDs)\n",
        "            index = author_names.index(name)          # devo ricavare la posizione dell'autore nella lista\n",
        "            author_id = author_IDs[index]                    # uso la posizione per estrarre l'ID corretto\n",
        "        except:\n",
        "            print(i)\n",
        "            i += 1      # significa che non trovo l'articolo su scopus, la query non dà risultati, quindi ne uso un'altra\n",
        "                        # TODOs: aggiungere un flag sul post mongodb che dica non trovato su scopus\n",
        "    return title, author_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T13:30:03.283585Z",
          "iopub.execute_input": "2022-03-08T13:30:03.283907Z",
          "iopub.status.idle": "2022-03-08T13:30:03.291499Z",
          "shell.execute_reply.started": "2022-03-08T13:30:03.283876Z",
          "shell.execute_reply": "2022-03-08T13:30:03.290353Z"
        },
        "trusted": true,
        "id": "BmhIilFimGSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_affiliation_history(author_id):\n",
        "    \n",
        "    # Retrieve dei documenti dell'autore, dai queli ricaverò la storia di affiliazione ...\n",
        "    author = AuthorRetrieval(author_id)\n",
        "    docs = pd.DataFrame(author.get_documents(refresh=10))\n",
        "    \n",
        "    # Creo una variabile \"anno\" per ogni documento ...\n",
        "    docs['coverDate'] = pd.to_datetime(docs['coverDate'])\n",
        "    docs['Year'] = None\n",
        "    for idx, row in enumerate(docs['coverDate']):\n",
        "        docs['Year'][idx] = row.year\n",
        "\n",
        "\n",
        "    # ottengo un df dove ho la storia di affiliazione dell'autore, con il periodo\n",
        "    df = pd.DataFrame({}, columns = ['Affiliation', 'Year'])\n",
        "    \n",
        "    for idx, row in enumerate(docs['title']):\n",
        "        \n",
        "        \n",
        "        try:\n",
        "            lista_authors_ids = list(docs['author_ids'][idx].split(';'))           # splitto gli IDs degli autori\n",
        "            \n",
        "            lista_affiliation_IDs = list(docs['author_afids'][idx].split(';'))    # splitto i rispettivi IDs delle affiliazioni\n",
        "                                                                              #  splitto gli ID delle affiliazioni presenti\n",
        "            lista_aff_id = list(docs['afid'][idx].split(';'))                     \n",
        "        \n",
        "            lista_aff_name = list(docs['affilname'][idx].split(';'))              # splitto le affiliazioni \n",
        "            \n",
        "            indice_autore = lista_authors_ids.index(author_id)                    # cerco l'ordine dell'autore che mi interessa nella lista degli ID autori\n",
        "            \n",
        "            affiliation_id = lista_affiliation_IDs[indice_autore]                 # grazie all'ordine dato dagli ID degli autori, estraggo quello della sua affiliazione\n",
        "        \n",
        "            \n",
        "        except:                                                                   # se qualcosa fallisce nel blocco\n",
        "            continue                                                              # allora è missing o c'è un errore di qualità\n",
        "            \n",
        "            \n",
        "                       \n",
        "        try:\n",
        "            indice_aff = lista_aff_id.index(affiliation_id)                   # cerco tra gli ID delle affiliazioni quello che mi interessa\n",
        "            aff = lista_aff_name[indice_aff]                                  # estraggo il nome dell'affiliazione che mi interessa\n",
        "            df = df.append({'Affiliation': aff,                               # aggiungo una riga al mio df con affiliazione e anno\n",
        "                                'Year': docs['Year'][idx]}, ignore_index=True )\n",
        "                \n",
        "        except:\n",
        "            multi_affiliation = affiliation_id.split('-')\n",
        "            for idx2, affil in enumerate(multi_affiliation):\n",
        "                if affil != '':\n",
        "                    indice_aff = lista_aff_id.index(affil)\n",
        "                    aff = lista_aff_name[indice_aff]\n",
        "                    df = df.append({'Affiliation': aff, 'Year': docs['Year'][idx]}, ignore_index=True )\n",
        "                else:\n",
        "                    pass\n",
        "                                                                             \n",
        "            \n",
        "    start = df.groupby('Affiliation', as_index = False).min().sort_values(by = 'Year', ascending = False)               # df degli anni di inizio affiliazione\n",
        "    end = df.groupby('Affiliation', as_index = False).max().sort_values(by = 'Year', ascending = False)                 # df degli ultimi anni di affiliazione\n",
        "    history = pd.merge(start, end, on = 'Affiliation').sort_values(by = 'Year_y', ascending = False)   \n",
        "\n",
        "    history['Affiliation Period'] = ''\n",
        "    for idx, row in enumerate(history['Affiliation Period']):\n",
        "        if history['Year_x'][idx] == history['Year_y'][idx]:\n",
        "            history['Affiliation Period'][idx] = str(history['Year_x'][idx])\n",
        "        else:\n",
        "            history['Affiliation Period'][idx] = str(history['Year_x'][idx]) + ' - ' + str(history['Year_y'][idx])\n",
        "    history.drop(['Year_x','Year_y'], axis = 1, inplace = True)\n",
        "    \n",
        "    update = {'Affiliation': {}}\n",
        "    for idx3, row in enumerate(history['Affiliation']):\n",
        "        update['Affiliation'][row] = history['Affiliation Period'][idx3]\n",
        "    \n",
        "    return update\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T12:39:15.941022Z",
          "iopub.execute_input": "2022-03-08T12:39:15.941806Z",
          "iopub.status.idle": "2022-03-08T12:39:15.959394Z",
          "shell.execute_reply.started": "2022-03-08T12:39:15.941758Z",
          "shell.execute_reply": "2022-03-08T12:39:15.958369Z"
        },
        "trusted": true,
        "id": "TY7bg0ycmGSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "4Rx1Ucf7mGSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cursor = users.find()\n",
        "collection_data = [document for document in cursor]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T12:55:53.058216Z",
          "iopub.execute_input": "2022-03-08T12:55:53.058587Z",
          "iopub.status.idle": "2022-03-08T12:56:03.703901Z",
          "shell.execute_reply.started": "2022-03-08T12:55:53.058553Z",
          "shell.execute_reply": "2022-03-08T12:56:03.703194Z"
        },
        "trusted": true,
        "id": "9s2md3XcmGSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_queries"
      ],
      "metadata": {
        "trusted": true,
        "id": "fKmgxUc0mGSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153b93d4-2a5e-4e1f-fe3e-e9030a3bf1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TITLE-ABS-KEY ( Secrecy AND Analysis AND in AND NOMA AND FullDuplex AND Relaying AND Networks AND With AND Artificial AND Jamming ) ',\n",
              " 'TITLE-ABS-KEY ( Power AND Optimization AND for AND Secure AND mmWaveNOMA AND Network AND with AND Hybrid AND SUCU AND Grouping ) ',\n",
              " 'TITLE-ABS-KEY ( Secrecy AND Analysis AND for AND NOMA AND networks AND With AND a AND FullDuplex AND Jamming AND Relay ) ',\n",
              " 'TITLE-ABS-KEY ( Security AND Enhancement AND Using AND a AND Novel AND TwoSlot AND Cooperative AND NOMA AND Scheme ) ',\n",
              " 'TITLE-ABS-KEY ( Power AND Optimization AND for AND Enhancing AND Secrecy AND of AND Cooperative AND User AND Relaying AND NOMA AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( Secure AND Transmission AND via AND Beamforming AND Optimization AND for AND NOMA AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( Secure AND Transmission AND for AND Interference AND Networks AND User AND Selection AND and AND Transceiver AND Design ) ',\n",
              " 'TITLE-ABS-KEY ( Secrecy AND Analysis AND for AND Cooperative AND NOMA AND Networks AND With AND MultiAntenna AND FullDuplex AND Relay ) ',\n",
              " 'TITLE-ABS-KEY ( Secure AND Primary AND Transmission AND Assisted AND by AND a AND Secondary AND FullDuplex AND NOMA AND Relay ) ',\n",
              " 'TITLE-ABS-KEY ( Secure AND Transmission AND via AND Joint AND Precoding AND Optimization AND for AND Downlink AND MISO AND NOMA ) ',\n",
              " 'TITLE-ABS-KEY ( Privacy AND Preservation AND via AND Beamforming AND for AND NOMA ) ',\n",
              " 'TITLE-ABS-KEY ( FullDuplex AND Relay AND Assisted AND Secure AND Transmission AND for AND NOMA AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( User AND Selection AND and AND Transceiver AND Design AND for AND Secure AND Transmission AND in AND MIMO AND Interference AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( Optimization AND or AND Alignment AND Secure AND Primary AND Transmission AND Assisted AND by AND Secondary AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( Artificial AND Noise AND Assisted AND Secure AND Interference AND Networks AND With AND Wireless AND Power AND Transfer ) ',\n",
              " 'TITLE-ABS-KEY ( A AND Novel AND Spectrum AND Sharing AND Scheme AND Assisted AND by AND Secondary AND NOMA AND Relay ) ',\n",
              " 'TITLE-ABS-KEY ( Secondary AND Transceiver AND Design AND for AND Secure AND Primary AND Transmission ) ',\n",
              " 'TITLE-ABS-KEY ( Privacy AND Protection AND via AND Beamforming AND Optimization AND in AND MISO AND NOMA AND Networks ) ',\n",
              " 'TITLE-ABS-KEY ( UAVAided AND NOMA AND Networks AND with AND Optimization AND of AND Trajectory AND and AND Precoding ) ',\n",
              " 'TITLE-ABS-KEY ( Beneficial AND jamming AND design AND for AND interference AND alignment AND networks ) ',\n",
              " 'TITLE-ABS-KEY ( An AND antieavesdropping AND interference AND alignment AND scheme AND with AND wireless AND power AND transfer ) ']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT-EpOeR0MCS",
        "outputId": "021dcade-48a7-438b-b594-3e1a3999c78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Secrecy Analysis in NOMA FullDuplex Relaying Networks With Artificial Jamming',\n",
              " 'Power Optimization for Secure mmWaveNOMA Network with Hybrid SUCU Grouping',\n",
              " 'Secrecy Analysis for NOMA networks With a FullDuplex Jamming Relay',\n",
              " 'Security Enhancement Using a Novel TwoSlot Cooperative NOMA Scheme',\n",
              " 'Power Optimization for Enhancing Secrecy of Cooperative User Relaying NOMA Networks',\n",
              " 'Secure Transmission via Beamforming Optimization for NOMA Networks',\n",
              " 'Secure Transmission for Interference Networks User Selection and Transceiver Design',\n",
              " 'Secrecy Analysis for Cooperative NOMA Networks With MultiAntenna FullDuplex Relay',\n",
              " 'Secure Primary Transmission Assisted by a Secondary FullDuplex NOMA Relay',\n",
              " 'Secure Transmission via Joint Precoding Optimization for Downlink MISO NOMA',\n",
              " 'Privacy Preservation via Beamforming for NOMA',\n",
              " 'FullDuplex Relay Assisted Secure Transmission for NOMA Networks',\n",
              " 'User Selection and Transceiver Design for Secure Transmission in MIMO Interference Networks',\n",
              " 'Optimization or Alignment Secure Primary Transmission Assisted by Secondary Networks',\n",
              " 'Artificial Noise Assisted Secure Interference Networks With Wireless Power Transfer',\n",
              " 'A Novel Spectrum Sharing Scheme Assisted by Secondary NOMA Relay',\n",
              " 'Secondary Transceiver Design for Secure Primary Transmission',\n",
              " 'Privacy Protection via Beamforming Optimization in MISO NOMA Networks',\n",
              " 'UAVAided NOMA Networks with Optimization of Trajectory and Precoding',\n",
              " 'Beneficial jamming design for interference alignment networks',\n",
              " 'An antieavesdropping interference alignment scheme with wireless power transfer']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, post in enumerate(collection_data[1:2]):\n",
        "    #print(idx)\n",
        "    lower, upper = get_titles_list(post)\n",
        "    post_queries = get_query_list(upper)\n",
        "    name = get_author_name(post) \n",
        "    #print(post_queries, name)                                           # ottengo il nome dell'autore\n",
        "    try:\n",
        "        title, author_id = get_author_id(query_list = post_queries[20:], name = name)\n",
        "        print('Scopus: ', title, ', DBLP: ', upper[20:] )\n",
        "    except:\n",
        "        print('author_id non trovato')"
      ],
      "metadata": {
        "id": "t-kkCYiKqAn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf4f571-7e59-4620-df01-392f0c893391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  eid                       doi   pii pubmed_id  \\\n",
            "0  2-s2.0-85042506474  10.1109/TVT.2017.2700475  None      None   \n",
            "\n",
            "                                               title subtype  \\\n",
            "0  Artificial Noise Assisted Secure Interference ...      ar   \n",
            "\n",
            "  subtypeDescription  creator                                 afid  \\\n",
            "0            Article  Zhao N.  60022020;60017592;60010365;60004538   \n",
            "\n",
            "                                           affilname  ...  pageRange  \\\n",
            "0  University of Warwick;Carleton University;The ...  ...  1087-1098   \n",
            "\n",
            "                                         description  \\\n",
            "0  Interference alignment (IA) is a remarkable te...   \n",
            "\n",
            "                                        authkeywords citedby_count openaccess  \\\n",
            "0  Artificial noise | interference alignment | pa...            80          0   \n",
            "\n",
            "      freetoread freetoreadLabel fund_acr   fund_no  \\\n",
            "0  repositoryvor           Green     NSFC  61671101   \n",
            "\n",
            "                                   fund_sponsor  \n",
            "0  National Natural Science Foundation of China  \n",
            "\n",
            "[1 rows x 36 columns]\n",
            "['Zhao, Nan', 'Cao, Yang', 'Yu, F. Richard', 'Chen, Yunfei', 'Jin, Minglu', 'Leung, Victor C.M.'] ['45562028800', '57193434067', '57213980384', '57202208700', '7202559277', '7102336029']\n",
            "Scopus:  Artificial Noise Assisted Secure Interference Networks with Wireless Power Transfer , DBLP:  ['An antieavesdropping interference alignment scheme with wireless power transfer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(post_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv2mQAZKqDfj",
        "outputId": "e1e1c85b-e1dd-4241-db05-a901fb28efcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TITLE-ABS-KEY ( Parallel AND algorithms AND for AND islanded AND microgrid AND with AND photovoltaic AND and AND energy AND storage AND systems AND planning AND optimization AND problem AND Material AND selection AND and AND quantity AND demand AND optimization ) ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Itero sui documenti presenti nel mio db, recupero le informazioni di cui ho bisogno da Scopus,\n",
        "# le elaboro come mi servono e faccio l'update su mongo db\n",
        "\n",
        "for idx, post in enumerate(collection_data[1:2]):\n",
        "    #print(idx)\n",
        "    lower, upper = get_titles_list(post)                                     # ritorna la lista lower per il matching e upper per le query\n",
        "    post_queries = get_query_list(upper)                                     # ottengo la lista di query\n",
        "    name = get_author_name(post)                                            # ottengo il nome dell'autore\n",
        "    try:\n",
        "        author_id = get_author_id(query_list = post_queries, name = name)       # ottengo l'ID dell'autore, se non lo trovo significa che non ho trovato suoi\n",
        "                                                                                # articoli su scopus, quindi aggiungo un flag di errore\n",
        "    except: \n",
        "        users.update_one({'_id': post['_id']},\n",
        "                     {'$set': {'Query Error': 'Articles not found in Scopus'}}, \n",
        "                     upsert=False)\n",
        "        continue\n",
        "    \n",
        "    history = get_affiliation_history(author_id)                            # ottengo il json contenente la storia di affiliazione \n",
        "    users.update_one({'_id': post['_id']},                                  # integro l'informazione nei singoli documenti su mongodb\n",
        "                     {'$set': history}, \n",
        "                     upsert=False)\n",
        "    users.update_one({'_id': post['_id']},                                  # integro l'informazione nei singoli documenti su mongodb\n",
        "                     {'$set': {'ScopusID': author_id}}, \n",
        "                     upsert=False)\n",
        "    "
      ],
      "metadata": {
        "id": "cpEkVq5rtLSJ",
        "outputId": "77ffd6ab-dd1d-48b4-a6f0-ba3817f06237",
        "execution": {
          "iopub.status.busy": "2022-03-08T13:30:17.315731Z",
          "iopub.execute_input": "2022-03-08T13:30:17.316071Z",
          "iopub.status.idle": "2022-03-08T13:30:17.596848Z",
          "shell.execute_reply.started": "2022-03-08T13:30:17.316024Z",
          "shell.execute_reply": "2022-03-08T13:30:17.595749Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "1\n",
            "                  eid                        doi                pii pubmed_id  \\\n",
            "0  2-s2.0-85116905893  10.1016/j.chb.2021.107042  S0747563221003654      None   \n",
            "\n",
            "                                               title subtype  \\\n",
            "0  Engaging voluntary contributions in online rev...      ar   \n",
            "\n",
            "  subtypeDescription creator                        afid  \\\n",
            "0            Article   Ma D.  60033100;60031846;60014724   \n",
            "\n",
            "                                           affilname  ... pageRange  \\\n",
            "0  Nanjing University;University of South Austral...  ...      None   \n",
            "\n",
            "                                         description  \\\n",
            "0  Employing a hierarchical badges system to sust...   \n",
            "\n",
            "                                        authkeywords citedby_count openaccess  \\\n",
            "0  Hierarchical badges system | Incentive mechani...             1          0   \n",
            "\n",
            "  freetoread freetoreadLabel fund_acr      fund_no  \\\n",
            "0       None            None     NSFC  19KJA510011   \n",
            "\n",
            "                                   fund_sponsor  \n",
            "0  National Natural Science Foundation of China  \n",
            "\n",
            "[1 rows x 36 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  eid                doi   pii pubmed_id  \\\n",
            "0  2-s2.0-85120374573  10.1002/int.22772  None      None   \n",
            "\n",
            "                                               title subtype  \\\n",
            "0  Recurrent spiking neural network with dynamic ...      ar   \n",
            "\n",
            "  subtypeDescription  creator                        afid  \\\n",
            "0            Article  Wang Z.  60032744;60025785;60010953   \n",
            "\n",
            "                                           affilname  ...  pageRange  \\\n",
            "0  Shanghai University of Finance and Economics;S...  ...  2242-2265   \n",
            "\n",
            "                                         description authkeywords  \\\n",
            "0  In recent years, spiking neural networks (SNNs...         None   \n",
            "\n",
            "  citedby_count openaccess freetoread freetoreadLabel fund_acr      fund_no  \\\n",
            "0             0          0       None            None     NSFC  19ZR1402000   \n",
            "\n",
            "                             fund_sponsor  \n",
            "0  Natural Science Foundation of Shanghai  \n",
            "\n",
            "[1 rows x 36 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LPpviSPcmGSj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}